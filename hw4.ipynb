{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# coding=utf-8\n",
    "import jieba \n",
    "from opencc import OpenCC\n",
    "cc = OpenCC('s2twp')\n",
    "import json\n",
    "import re\n",
    "def init():\n",
    "    files = ['AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ','AK','AL']\n",
    "    #files = ['AA']\n",
    "    text = []\n",
    "    for fi in files:\n",
    "        for i in range(0, 100):\n",
    "            if i%20==0:\n",
    "                print('./wiki_zh/{}/wiki_{}'.format(fi,str(i).zfill(2)))\n",
    "            with open('./wiki_zh/{}/wiki_{}'.format(fi,str(i).zfill(2)),'r', encoding = 'utf-8') as file_open:\n",
    "                data = []\n",
    "                for line in file_open:\n",
    "                    data = json.loads(line)\n",
    "                    x = re.sub('\\s+','',cc.convert(data['text']))\n",
    "                    text.append(re.sub('[^\\u4e00-\\u9fa5]+','',x)+'\\n')\n",
    "    for j in range(0,74):\n",
    "        with open('./wiki_zh/AL/wiki_{}'.format(str(j).zfill(2)),'r', encoding = 'utf-8') as file_open:\n",
    "            if j%20==0:\n",
    "                print('./wiki_zh/AL/wiki_{}'.format(str(j).zfill(2)))\n",
    "            data = []\n",
    "            for line in file_open:\n",
    "                data = json.loads(line)\n",
    "                x = re.sub('\\s+','',cc.convert(data['text']))\n",
    "                text.append(re.sub('[^\\u4e00-\\u9fa5]+','',x)+'\\n')\n",
    "\n",
    "    with open('output.txt', 'w+') as f:\n",
    "        for i in text:\n",
    "            f.write(i)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "init()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./wiki_zh/AA/wiki_00\n",
      "./wiki_zh/AA/wiki_20\n",
      "./wiki_zh/AA/wiki_40\n",
      "./wiki_zh/AA/wiki_60\n",
      "./wiki_zh/AA/wiki_80\n",
      "./wiki_zh/AB/wiki_00\n",
      "./wiki_zh/AB/wiki_20\n",
      "./wiki_zh/AB/wiki_40\n",
      "./wiki_zh/AB/wiki_60\n",
      "./wiki_zh/AB/wiki_80\n",
      "./wiki_zh/AC/wiki_00\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g9/__yhhv7d0xx59_jssnmpjhwh0000gn/T/ipykernel_26312/3388742132.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/g9/__yhhv7d0xx59_jssnmpjhwh0000gn/T/ipykernel_26312/1519885121.py\u001b[0m in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^\\u4e00-\\u9fa5]+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/opencc/opencc.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;31m# Work with the text string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# Append converted string to result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_string_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_chain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;31m# Work with the separator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/opencc/opencc.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(self, string, dictionary)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_parse_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/opencc/opencc.py\u001b[0m in \u001b[0;36mcreate_parse_tree\u001b[0;34m(self, test_dict_list)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mworking_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworking_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__findMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength_hint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                     \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/opencc/opencc.py\u001b[0m in \u001b[0;36m__findMatch\u001b[0;34m(self, string, test_dict, hint)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;31m# Loop through trying successively smaller substrings in the dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest_len\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m                     \u001b[0;31m# Match found.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "import logging\n",
    "def split_word():\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    jieba.set_dictionary('./dict.txt.big')\n",
    "    stopword_set = set()\n",
    "    with open('./stop_words.txt','r', encoding='utf-8') as stopwords:\n",
    "        for stopword in stopwords:\n",
    "            stopword_set.add(stopword.strip('\\n'))\n",
    "\n",
    "    output = open('wiki_seg.txt', 'w', encoding='utf-8')\n",
    "    with open('output.txt', 'r', encoding='utf-8') as content :\n",
    "        for texts_num, line in enumerate(content):\n",
    "            line = line.strip('\\n')\n",
    "            words = jieba.cut(line, cut_all=False)\n",
    "            for word in words:\n",
    "                if word not in stopword_set:\n",
    "                    output.write(word + ' ')\n",
    "            output.write('\\n')\n",
    "\n",
    "            if (texts_num + 1) % 10000 == 0:\n",
    "                logging.info(\"已完成前 %d 行的斷詞\" % (texts_num + 1))\n",
    "    output.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building prefix dict from /Users/zhangxinyu/Desktop/NLP_HW4/dict.txt.big ...\n",
      "2021-08-13 12:53:53,331 : DEBUG : Building prefix dict from /Users/zhangxinyu/Desktop/NLP_HW4/dict.txt.big ...\n",
      "Loading model from cache /var/folders/g9/__yhhv7d0xx59_jssnmpjhwh0000gn/T/jieba.ube3f6a8139837e1b741098a736f9c4d5.cache\n",
      "2021-08-13 12:53:53,333 : DEBUG : Loading model from cache /var/folders/g9/__yhhv7d0xx59_jssnmpjhwh0000gn/T/jieba.ube3f6a8139837e1b741098a736f9c4d5.cache\n",
      "Loading model cost 1.507 seconds.\n",
      "2021-08-13 12:53:54,839 : DEBUG : Loading model cost 1.507 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2021-08-13 12:53:54,841 : DEBUG : Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "split_word()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "def main():\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    sentences = word2vec.LineSentence(u\"wiki_seg.txt\")\n",
    "    model = word2vec.Word2Vec(sentences,vector_size=300)\n",
    "\n",
    "    #保存模型，供日後使用\n",
    "    model.save(\"word2vec.model\")\n",
    "\n",
    "\n",
    "main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-13 13:04:09,872 : INFO : collecting all words and their counts\n",
      "2021-08-13 13:04:09,889 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-08-13 13:04:09,922 : INFO : collected 24635 word types from a corpus of 138638 raw words and 14 sentences\n",
      "2021-08-13 13:04:09,923 : INFO : Creating a fresh vocabulary\n",
      "2021-08-13 13:04:09,951 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 4301 unique words (17.45889993911102%% of original 24635, drops 20334)', 'datetime': '2021-08-13T13:04:09.951821', 'gensim': '4.0.1', 'python': '3.7.6 (default, Apr 24 2021, 01:03:20) \\n[Clang 12.0.0 (clang-1200.0.32.29)]', 'platform': 'Darwin-20.5.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-08-13 13:04:09,953 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 108371 word corpus (78.1683232591353%% of original 138638, drops 30267)', 'datetime': '2021-08-13T13:04:09.953084', 'gensim': '4.0.1', 'python': '3.7.6 (default, Apr 24 2021, 01:03:20) \\n[Clang 12.0.0 (clang-1200.0.32.29)]', 'platform': 'Darwin-20.5.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-08-13 13:04:09,986 : INFO : deleting the raw counts dictionary of 24635 items\n",
      "2021-08-13 13:04:09,987 : INFO : sample=0.001 downsamples 37 most-common words\n",
      "2021-08-13 13:04:09,989 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 100629.86062085294 word corpus (92.9%% of prior 108371)', 'datetime': '2021-08-13T13:04:09.989817', 'gensim': '4.0.1', 'python': '3.7.6 (default, Apr 24 2021, 01:03:20) \\n[Clang 12.0.0 (clang-1200.0.32.29)]', 'platform': 'Darwin-20.5.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-08-13 13:04:10,045 : INFO : estimated required memory for 4301 words and 200 dimensions: 9032100 bytes\n",
      "2021-08-13 13:04:10,046 : INFO : resetting layer weights\n",
      "2021-08-13 13:04:10,051 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-08-13T13:04:10.051434', 'gensim': '4.0.1', 'python': '3.7.6 (default, Apr 24 2021, 01:03:20) \\n[Clang 12.0.0 (clang-1200.0.32.29)]', 'platform': 'Darwin-20.5.0-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2021-08-13 13:04:10,052 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 4301 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-08-13T13:04:10.052357', 'gensim': '4.0.1', 'python': '3.7.6 (default, Apr 24 2021, 01:03:20) \\n[Clang 12.0.0 (clang-1200.0.32.29)]', 'platform': 'Darwin-20.5.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "2021-08-13 13:04:10,153 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-13 13:04:10,159 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-13 13:04:10,165 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-13 13:04:10,166 : INFO : EPOCH - 1 : training on 138638 raw words (100761 effective words) took 0.1s, 901530 effective words/s\n",
      "2021-08-13 13:04:10,274 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-13 13:04:10,276 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-13 13:04:10,287 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-13 13:04:10,288 : INFO : EPOCH - 2 : training on 138638 raw words (100594 effective words) took 0.1s, 843631 effective words/s\n",
      "2021-08-13 13:04:10,387 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-13 13:04:10,393 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-13 13:04:10,399 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-13 13:04:10,400 : INFO : EPOCH - 3 : training on 138638 raw words (100677 effective words) took 0.1s, 916305 effective words/s\n",
      "2021-08-13 13:04:10,498 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-13 13:04:10,502 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-13 13:04:10,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-13 13:04:10,510 : INFO : EPOCH - 4 : training on 138638 raw words (100700 effective words) took 0.1s, 943337 effective words/s\n",
      "2021-08-13 13:04:10,613 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-13 13:04:10,620 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-13 13:04:10,624 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-13 13:04:10,625 : INFO : EPOCH - 5 : training on 138638 raw words (100571 effective words) took 0.1s, 889372 effective words/s\n",
      "2021-08-13 13:04:10,626 : INFO : Word2Vec lifecycle event {'msg': 'training on 693190 raw words (503303 effective words) took 0.6s, 877808 effective words/s', 'datetime': '2021-08-13T13:04:10.626252', 'gensim': '4.0.1', 'python': '3.7.6 (default, Apr 24 2021, 01:03:20) \\n[Clang 12.0.0 (clang-1200.0.32.29)]', 'platform': 'Darwin-20.5.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "2021-08-13 13:04:10,627 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=4301, vector_size=200, alpha=0.025)', 'datetime': '2021-08-13T13:04:10.627479', 'gensim': '4.0.1', 'python': '3.7.6 (default, Apr 24 2021, 01:03:20) \\n[Clang 12.0.0 (clang-1200.0.32.29)]', 'platform': 'Darwin-20.5.0-x86_64-i386-64bit', 'event': 'created'}\n",
      "2021-08-13 13:04:10,628 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-08-13T13:04:10.628281', 'gensim': '4.0.1', 'python': '3.7.6 (default, Apr 24 2021, 01:03:20) \\n[Clang 12.0.0 (clang-1200.0.32.29)]', 'platform': 'Darwin-20.5.0-x86_64-i386-64bit', 'event': 'saving'}\n",
      "2021-08-13 13:04:10,629 : INFO : not storing attribute cum_table\n",
      "2021-08-13 13:04:10,641 : INFO : saved word2vec.model\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "model = word2vec.Word2Vec.load(\"word2vec.model\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-13 13:04:14,707 : INFO : loading Word2Vec object from word2vec.model\n",
      "2021-08-13 13:04:14,714 : INFO : loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "2021-08-13 13:04:14,715 : INFO : setting ignored attribute cum_table to None\n",
      "2021-08-13 13:04:14,770 : INFO : Word2Vec lifecycle event {'fname': 'word2vec.model', 'datetime': '2021-08-13T13:04:14.770124', 'gensim': '4.0.1', 'python': '3.7.6 (default, Apr 24 2021, 01:03:20) \\n[Clang 12.0.0 (clang-1200.0.32.29)]', 'platform': 'Darwin-20.5.0-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "word = model.wv.most_similar(u'電腦')\n",
    "for t in word:\n",
    "    print(t[0],t[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "領域 0.9992326498031616\n",
      "數學 0.9992170333862305\n",
      "科學 0.9990915060043335\n",
      "方法 0.9989305734634399\n",
      "理論 0.9988278746604919\n",
      "程式 0.9988192319869995\n",
      "作業系統 0.9987596869468689\n",
      "學科 0.9987593293190002\n",
      "計算 0.9987465143203735\n",
      "使用 0.9987353086471558\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('3.7.6': pyenv)"
  },
  "interpreter": {
   "hash": "7fc41b1a7acd303dd356c32eae0bc8ee4149514fe8a099b2279ea3ac2a654e9b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}